# Environment variables for Benchmarking-LLM-Models
# Copy this file to `.env` and update the values before running benchmarks.

# OpenAI API key for OpenAI Evals and HELM integrations
OPENAI_API_KEY=sk-...

# Anthropic API key (if benchmarking Claude models)
ANTHROPIC_API_KEY=anthropic-...

# Google API key (if benchmarking Gemini models)
GOOGLE_API_KEY=google-...

# Path to local Hugging Face token for LM Eval Harness
HUGGINGFACE_HUB_TOKEN=hf_...
